{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "from src.word_to_embedding import WordToEmbedding\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2e = WordToEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label_mapping(data: pd.DataFrame):\n",
    "    label_to_id = {item: i for i, item in enumerate(set(data['произход']))}\n",
    "    id_to_label = {index: label for label, index in label_to_id.items()}\n",
    "\n",
    "    return label_to_id, id_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoanwordsDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, label_to_id: dict[str, int], embeddeing_engine: WordToEmbedding):\n",
    "        self.__data = data\n",
    "        self.__len = self.__data.shape[0]\n",
    "        \n",
    "        self.__label_mapping = label_to_id\n",
    "        self.__embeddeing_engine = embeddeing_engine\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.__len\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[str, str]:\n",
    "        entry = self.__data.iloc[index]\n",
    "\n",
    "        word = entry['дума']\n",
    "        origin = entry['произход']\n",
    "        word_tensor = self.__embeddeing_engine.get_embedding(word)\n",
    "        origin_tensor = self.__label_mapping[origin]\n",
    "\n",
    "        word_tensor_shape = word_tensor.shape\n",
    "        word_tensor = word_tensor.reshape((word_tensor_shape[0], 1, word_tensor_shape[1]))\n",
    "\n",
    "        return word, word_tensor, origin, origin_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoanwordClassifier(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n",
    "        super().__init__()\n",
    "        self.__hidden_size = hidden_size\n",
    "\n",
    "        self.__i2h = nn.Linear(input_size + self.__hidden_size, self.__hidden_size).to(device)\n",
    "        self.__h2h = nn.Linear(hidden_size, hidden_size).to(device)\n",
    "        self.__h2h_2 = nn.Linear(hidden_size, hidden_size).to(device)\n",
    "        self.__h2o = nn.Linear(hidden_size, output_size).to(device)\n",
    "        self.__softmax = nn.LogSoftmax(dim=1).to(device)\n",
    "\n",
    "    def forward(self, input_tensor, hidden):\n",
    "        combined = torch.cat((input_tensor.to(device), hidden.to(device)), 1).to(device)\n",
    "        hidden = F.tanh(self.__i2h(combined).to(device) + self.__h2h(hidden.to(device)).to(device)).to(device)\n",
    "        hidden = F.tanh(hidden + self.__h2h_2(hidden.to(device)).to(device)).to(device)\n",
    "        output = self.__h2o(hidden).to(device)\n",
    "        output = self.__softmax(output).to(device)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.__hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_from_output(output, id_to_label):\n",
    "    top_n, top_i = output.topk(1)\n",
    "\n",
    "    category_i = top_i[0].item()\n",
    "    return id_to_label[category_i], category_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model: LoanwordClassifier, train_dataloader, loss_fn,  id_to_label, learning_rate=0.005):\n",
    "    sum_loss = 0\n",
    "    for word, word_tensor, label, label_tensor in tqdm(train_dataloader):\n",
    "        word_tensor = word_tensor[0]\n",
    "        hidden = model.init_hidden()\n",
    "        model.zero_grad()\n",
    "\n",
    "        for syllable_embedding in word_tensor:\n",
    "            output, hidden = model(syllable_embedding, hidden)\n",
    "        \n",
    "        loss = loss_fn(output.to(device), label_tensor.to(device))\n",
    "        loss.backward()\n",
    "\n",
    "        for p in model.parameters():\n",
    "            p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "        \n",
    "        sum_loss += loss.item()\n",
    "\n",
    "    return sum_loss / len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & Test loop\n",
    "def train_loop(model: LoanwordClassifier, train_dataloader, epochs, loss_fn, id_to_label, learning_rate=0.005):\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        epoch_loss = train_epoch(model, train_dataloader, loss_fn, id_to_label, learning_rate)\n",
    "        print(f\"Epoch: {epoch}, loss: {epoch_loss:>7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(model: LoanwordClassifier, test_dataloader, id_to_label):\n",
    "    predicted_ids = []\n",
    "    actual_ids = []\n",
    "    for word, word_tensor, label, label_tensor in tqdm(test_dataloader):\n",
    "        word_tensor = word_tensor[0]\n",
    "\n",
    "        hidden = model.init_hidden()\n",
    "\n",
    "        for syllable_embedding in word_tensor:\n",
    "            output, hidden = model(syllable_embedding, hidden)\n",
    "\n",
    "        predicted_label, predicted_label_id = category_from_output(output, id_to_label)\n",
    "        # print(predicted_label, predicted_label_id)\n",
    "        predicted_ids.append(predicted_label_id)\n",
    "        actual_ids.append(label_tensor)\n",
    "    \n",
    "    return predicted_ids, actual_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution(train_data, label_to_id):\n",
    "    counts = train_data['произход'].value_counts(normalize=True)\n",
    "    weights = sorted(zip(counts.keys(), counts), key=lambda x: label_to_id[x[0]])\n",
    "    weights = list(map(lambda x: x[1], weights))\n",
    "    return torch.Tensor(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/d/Projects/masters-thesis/data/loanwords_5k_bg_words.csv'\n",
    "data = pd.read_csv(path)\n",
    "label_to_id, id_to_label = generate_label_mapping(data)\n",
    "\n",
    "# Running the model with normal labels \n",
    "train_data, test_data = train_test_split(data, random_state=RANDOM_STATE)\n",
    "\n",
    "\n",
    "train_dataset = LoanwordsDataset(train_data, label_to_id, embeddeing_engine=w2e)\n",
    "train_dataloader = DataLoader(train_dataset)\n",
    "\n",
    "test_dataset = LoanwordsDataset(test_data, label_to_id, embeddeing_engine=w2e)\n",
    "test_dataloader = DataLoader(test_dataset)\n",
    "\n",
    "model = LoanwordClassifier(input_size=512, hidden_size=1024, output_size=len(label_to_id))\n",
    "distribution = get_distribution(train_data, label_to_id).to(device)\n",
    "loss_fn = nn.NLLLoss(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1, 512)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7625/7625 [01:01<00:00, 123.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 1.439886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7625/7625 [00:56<00:00, 136.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 1.219642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7625/7625 [00:45<00:00, 169.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss: 1.098222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7625/7625 [01:02<00:00, 122.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, loss: 0.998513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7625/7625 [01:07<00:00, 113.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, loss: 0.921239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7625/7625 [01:17<00:00, 98.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, loss: 0.882490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7625/7625 [01:06<00:00, 114.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, loss: 0.808037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7625/7625 [01:09<00:00, 109.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, loss: 0.759556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7625/7625 [01:06<00:00, 115.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, loss: 0.756344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7625/7625 [01:03<00:00, 120.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, loss: 0.705568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7625/7625 [01:07<00:00, 113.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 0.734255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7625/7625 [01:10<00:00, 108.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, loss: 0.741421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7625/7625 [01:11<00:00, 106.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, loss: 0.708927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7625/7625 [01:11<00:00, 106.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, loss: 0.689930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7625/7625 [01:12<00:00, 105.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, loss: 0.638702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, train_dataloader, epochs=15, loss_fn=loss_fn, id_to_label=id_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "torch.save(model.state_dict(), f'models/classifier-{today_date}-1024hidden-15epochs-5kbgwords.pth')\n",
    "\n",
    "id_to_label_json = json.dumps(id_to_label)\n",
    "with open(f'models/id-to-label-{today_date}-1024hidden-15epochs-5kbgwords.json', 'w+') as fp:\n",
    "    fp.write(id_to_label_json)\n",
    "\n",
    "\n",
    "label_to_id_json = json.dumps(label_to_id)\n",
    "with open(f'models/label-to-id-{today_date}-1024hidden-15epochs-5kbgwords', 'w+') as fp:\n",
    "    fp.write(label_to_id_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14327/14327 [02:15<00:00, 106.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.930788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14327/14327 [02:14<00:00, 106.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 0.797522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14327/14327 [02:05<00:00, 114.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss: 0.727542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14327/14327 [02:00<00:00, 119.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, loss: 0.669049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14327/14327 [01:55<00:00, 124.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, loss: 0.637900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14327/14327 [01:54<00:00, 125.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, loss: 0.599897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14327/14327 [01:55<00:00, 123.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, loss: 0.583261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14327/14327 [01:56<00:00, 123.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, loss: 0.564660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14327/14327 [01:55<00:00, 124.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, loss: 0.548564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14327/14327 [01:54<00:00, 125.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, loss: 0.548488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14327/14327 [01:55<00:00, 124.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 0.545569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14327/14327 [01:57<00:00, 121.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, loss: 0.539187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14327/14327 [01:58<00:00, 120.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, loss: 0.525178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14327/14327 [02:01<00:00, 118.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, loss: 0.529139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14327/14327 [01:56<00:00, 122.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, loss: 0.528721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = '/mnt/d/Projects/masters-thesis/data/loanwords_13k_bg_words.csv'\n",
    "data = pd.read_csv(path)\n",
    "label_to_id, id_to_label = generate_label_mapping(data)\n",
    "\n",
    "# Running the model with normal labels \n",
    "train_data, test_data = train_test_split(data, random_state=RANDOM_STATE)\n",
    "\n",
    "\n",
    "train_dataset = LoanwordsDataset(train_data, label_to_id, embeddeing_engine=w2e)\n",
    "train_dataloader = DataLoader(train_dataset)\n",
    "\n",
    "test_dataset = LoanwordsDataset(test_data, label_to_id, embeddeing_engine=w2e)\n",
    "test_dataloader = DataLoader(test_dataset)\n",
    "\n",
    "model = LoanwordClassifier(input_size=512, hidden_size=1024, output_size=len(label_to_id))\n",
    "distribution = get_distribution(train_data, label_to_id).to(device)\n",
    "loss_fn = nn.NLLLoss(distribution)\n",
    "\n",
    "train_loop(model, train_dataloader, epochs=15, loss_fn=loss_fn, id_to_label=id_to_label)\n",
    "\n",
    "from datetime import datetime\n",
    "today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "torch.save(model.state_dict(), f'models/classifier-{today_date}-1024hidden-15epochs-13kbgwords.pth')\n",
    "\n",
    "id_to_label_json = json.dumps(id_to_label)\n",
    "with open(f'models/id-to-label-{today_date}-1024hidden-15epochs-13kbgwords.json', 'w+') as fp:\n",
    "    fp.write(id_to_label_json)\n",
    "\n",
    "\n",
    "label_to_id_json = json.dumps(label_to_id)\n",
    "with open(f'models/label-to-id-{today_date}-1024hidden-15epochs-13kbgwords', 'w+') as fp:\n",
    "    fp.write(label_to_id_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27032/27032 [02:40<00:00, 167.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.588038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27032/27032 [02:36<00:00, 173.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 0.510282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27032/27032 [02:35<00:00, 173.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss: 0.470376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27032/27032 [02:33<00:00, 176.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, loss: 0.442017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27032/27032 [02:31<00:00, 178.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, loss: 0.428195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27032/27032 [02:31<00:00, 178.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, loss: 0.408192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27032/27032 [02:29<00:00, 180.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, loss: 0.385043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27032/27032 [02:30<00:00, 179.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, loss: 0.403255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27032/27032 [02:30<00:00, 180.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, loss: 0.385706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27032/27032 [02:29<00:00, 180.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, loss: 0.370143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27032/27032 [02:29<00:00, 180.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 0.387335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27032/27032 [02:29<00:00, 180.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, loss: 0.379751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27032/27032 [02:29<00:00, 180.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, loss: 0.390908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27032/27032 [02:30<00:00, 180.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, loss: 0.382018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27032/27032 [02:30<00:00, 179.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, loss: 0.371013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = '/mnt/d/Projects/masters-thesis/data/loanwords_30k_bg_words.csv'\n",
    "data = pd.read_csv(path)\n",
    "label_to_id, id_to_label = generate_label_mapping(data)\n",
    "\n",
    "# Running the model with normal labels \n",
    "train_data, test_data = train_test_split(data, random_state=RANDOM_STATE)\n",
    "\n",
    "\n",
    "train_dataset = LoanwordsDataset(train_data, label_to_id, embeddeing_engine=w2e)\n",
    "train_dataloader = DataLoader(train_dataset)\n",
    "\n",
    "test_dataset = LoanwordsDataset(test_data, label_to_id, embeddeing_engine=w2e)\n",
    "test_dataloader = DataLoader(test_dataset)\n",
    "\n",
    "model = LoanwordClassifier(input_size=512, hidden_size=1024, output_size=len(label_to_id))\n",
    "distribution = get_distribution(train_data, label_to_id).to(device)\n",
    "loss_fn = nn.NLLLoss(distribution)\n",
    "\n",
    "train_loop(model, train_dataloader, epochs=15, loss_fn=loss_fn, id_to_label=id_to_label)\n",
    "\n",
    "from datetime import datetime\n",
    "today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "torch.save(model.state_dict(), f'models/classifier-{today_date}-1024hidden-15epochs-30kbgwords.pth')\n",
    "\n",
    "id_to_label_json = json.dumps(id_to_label)\n",
    "with open(f'models/id-to-label-{today_date}-1024hidden-15epochs-30kbgwords.json', 'w+') as fp:\n",
    "    fp.write(id_to_label_json)\n",
    "\n",
    "\n",
    "label_to_id_json = json.dumps(label_to_id)\n",
    "with open(f'models/label-to-id-{today_date}-1024hidden-15epochs-30kbgwords', 'w+') as fp:\n",
    "    fp.write(label_to_id_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
