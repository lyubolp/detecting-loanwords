{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from src.word_to_embedding import WordToEmbedding\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyubolp/detecting-loanwords/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "/home/lyubolp/detecting-loanwords/src/transcription_dataset_single_word.py:44: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(row[0], str):\n",
      "/home/lyubolp/detecting-loanwords/src/transcription_dataset_single_word.py:45: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  word = row[0].strip()\n",
      "/home/lyubolp/detecting-loanwords/src/transcription_dataset_single_word.py:49: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(row[1], str):\n",
      "/home/lyubolp/detecting-loanwords/src/transcription_dataset_single_word.py:50: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  transcription = row[1].strip()\n"
     ]
    }
   ],
   "source": [
    "w2e = WordToEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoanwordsDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, label_to_id: dict[str, int], embeddeing_engine: WordToEmbedding):\n",
    "        self.__data = data\n",
    "        self.__len = self.__data.shape[0]\n",
    "        \n",
    "        self.__label_mapping = label_to_id\n",
    "        self.__embeddeing_engine = embeddeing_engine\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.__len\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[str, str]:\n",
    "        entry = self.__data.iloc[index]\n",
    "\n",
    "        word = entry['дума']\n",
    "        origin = entry['произход']\n",
    "        word_tensor = self.__embeddeing_engine.get_embedding(word)\n",
    "        origin_tensor = self.__label_mapping[origin]\n",
    "\n",
    "        word_tensor_shape = word_tensor.shape\n",
    "        word_tensor = word_tensor.reshape((word_tensor_shape[0], 1, word_tensor_shape[1]))\n",
    "\n",
    "        return word, word_tensor, origin, origin_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoanwordClassifier(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n",
    "        super().__init__()\n",
    "        self.__hidden_size = hidden_size\n",
    "\n",
    "        self.__i2h = nn.Linear(input_size + self.__hidden_size, self.__hidden_size).to(device)\n",
    "        self.__h2o = nn.Linear(hidden_size, output_size).to(device)\n",
    "        self.__softmax = nn.LogSoftmax(dim=1).to(device)\n",
    "\n",
    "    def forward(self, input_tensor, hidden):\n",
    "        combined = torch.cat((input_tensor.to(device), hidden.to(device)), 1).to(device)\n",
    "        hidden = self.__i2h(combined).to(device)\n",
    "        output = self.__h2o(hidden).to(device)\n",
    "        output = self.__softmax(output).to(device)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.__hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_from_output(output, id_to_label):\n",
    "    top_n, top_i = output.topk(1)\n",
    "\n",
    "    category_i = top_i[0].item()\n",
    "    return id_to_label[category_i], category_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(word, model, id_to_label):\n",
    "    word_tensor = torch.Tensor(w2e.get_embedding(word))\n",
    "\n",
    "    word_tensor_shape = word_tensor.shape\n",
    "    word_tensor = word_tensor.reshape((word_tensor_shape[0], 1, word_tensor_shape[1]))\n",
    "\n",
    "    hidden = model.init_hidden()\n",
    "\n",
    "    for syllable_embedding in word_tensor:\n",
    "        output, hidden = model(syllable_embedding, hidden)\n",
    "    \n",
    "    # predicted_label, predicted_label_id = category_from_output(output, id_to_label)\n",
    "    \n",
    "    print(output.shape)\n",
    "    probabilities, label_ids = output.topk(5)\n",
    "\n",
    "    return {id_to_label[label_id.item()]: probability.item() for probability, label_id in zip(probabilities[0], label_ids[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/loanwords.csv'\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "with open('models/label-to-id-2024-01-24-1024hidden-10epochs.pth') as fp:\n",
    "    label_to_id = json.load(fp)\n",
    "\n",
    "id_to_label = {_id: label for label, _id in label_to_id.items()}\n",
    "\n",
    "model = LoanwordClassifier(input_size=512, hidden_size=1024, output_size=len(label_to_id))\n",
    "\n",
    "state_dict_path = 'models/classifier-2024-01-24-1024hidden-10epochs.pth'\n",
    "model.load_state_dict(torch.load(state_dict_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 17])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bg': -0.2701360285282135,\n",
       " 'fr': -2.4236598014831543,\n",
       " 'el': -2.6807174682617188,\n",
       " 'de': -3.7396557331085205,\n",
       " 'la': -4.143362522125244}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('рахат', model, id_to_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
