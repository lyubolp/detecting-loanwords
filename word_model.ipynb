{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from torch import Tensor\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "MAX_LENGTH = 71\n",
    "SOS_TOKEN = 69\n",
    "EOS_TOKEN = 70\n",
    "TEACHER_FORCING_RATIO = 0.5\n",
    "LEARNING_RATE = 0.01\n",
    "HIDDEN_SIZE = 256\n",
    "VOCABULARY_LIMIT = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input: torch.Tensor, hidden: torch.Tensor) -> torch.Tensor:\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self) -> torch.Tensor:\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "    \n",
    "    def forward(self, input_tensor, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input_tensor).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_tensor(content, target_size = MAX_LENGTH) -> torch.Tensor:\n",
    "    # Add padding to the end of the sentence, so that the length is equal to target_size\n",
    "    content.append(EOS_TOKEN)\n",
    "    tensor = torch.tensor(content, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "    # if tensor.size()[0] < target_size:\n",
    "    #     padding = torch.zeros(target_size - tensor.size()[0], 1, dtype=torch.int32, device=device)\n",
    "    #     tensor = torch.cat((tensor, padding), dim=0)\n",
    "        \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranscriptionDataset(Dataset):\n",
    "    def __init__(self, path_to_words: str = 'data/word-based/words.csv'):\n",
    "        self.__words = pd.read_csv(path_to_words).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.__words.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= self.__len__():\n",
    "            raise IndexError\n",
    "        \n",
    "        row = self.__words.iloc[idx]\n",
    "\n",
    "        input_tensor = sentence_to_tensor(json.loads(row[2]))\n",
    "        target_tensor = sentence_to_tensor(json.loads(row[3]))\n",
    "        return input_tensor, target_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, encoder: EncoderRNN, decoder: DecoderRNN,\n",
    "                 encoder_optimizer: optim.Optimizer, decoder_optimizer: optim.Optimizer,\n",
    "                 max_length: int = MAX_LENGTH):\n",
    "        self.__encoder = encoder.to(device)\n",
    "        self.__decoder = decoder.to(device)\n",
    "        self.__encoder_optimizer = encoder_optimizer\n",
    "        self.__decoder_optimizer = decoder_optimizer\n",
    "        self.__max_length = max_length\n",
    "        self.__loss = 0\n",
    "\n",
    "    def __init_train(self):\n",
    "        encoder_hidden = self.__encoder.init_hidden()\n",
    "\n",
    "        self.__encoder_optimizer.zero_grad()\n",
    "        self.__decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs = torch.zeros(self.__max_length, self.__encoder.hidden_size, device=device)\n",
    "\n",
    "        self.__loss = 0\n",
    "\n",
    "        return encoder_hidden, encoder_outputs\n",
    "    \n",
    "    def __encoder_train(self, encoder_outputs, input_tensor, encoder_hidden):\n",
    "        input_length = input_tensor.size(0)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = self.__encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "        return encoder_outputs\n",
    "\n",
    "    def __optimizers_step(self):\n",
    "        self.__encoder_optimizer.step()\n",
    "        self.__decoder_optimizer.step()\n",
    "\n",
    "    def __decoder_train(self, decoder_input, decoder_hidden, encoder_outputs, target_tensor, criterion):\n",
    "        target_length = target_tensor.size(0)\n",
    "        use_teacher_forcing = True if random.random() < TEACHER_FORCING_RATIO else False\n",
    "\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = self.__decoder(\n",
    "                    decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            if use_teacher_forcing:\n",
    "                decoder_input = target_tensor[di]\n",
    "            else:\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "            \n",
    "            self.__loss += criterion(decoder_output, target_tensor[di])\n",
    "\n",
    "            if use_teacher_forcing and decoder_input.item() == EOS_TOKEN:\n",
    "                break\n",
    "\n",
    "    def train(self, input_tensor: Tensor, target_tensor: Tensor, \n",
    "              criterion: nn.Module, max_length: int = MAX_LENGTH) -> tuple[float, float]:        \n",
    "\n",
    "        # Encoder training\n",
    "        encoder_hidden, encoder_outputs = self.__init_train()\n",
    "        encoder_outputs = self.__encoder_train(encoder_outputs, input_tensor, encoder_hidden)\n",
    "\n",
    "        # Decoder training\n",
    "        decoder_input = torch.tensor([[SOS_TOKEN]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        self.__decoder_train(decoder_input, decoder_hidden, encoder_outputs, target_tensor, criterion)\n",
    "        \n",
    "        # Optimizers step\n",
    "        self.__loss.backward()\n",
    "        self.__optimizers_step()\n",
    "\n",
    "        return self.__loss.item() / target_tensor.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(encoder: EncoderRNN, decoder: DecoderRNN, dataset: TranscriptionDataset,\n",
    "               epochs: int, print_every: int = 100):\n",
    "    print(f'Training with {epochs=}, {TEACHER_FORCING_RATIO=}, {LEARNING_RATE=}, {HIDDEN_SIZE=}, {VOCABULARY_LIMIT=}')\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=LEARNING_RATE)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "\n",
    "    trainer = Trainer(encoder, decoder, encoder_optimizer, decoder_optimizer)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        # for iteration, (input_tensor, target_tensor) in tqdm.tqdm(enumerate(dataset)):\n",
    "        for iteration in range(VOCABULARY_LIMIT):\n",
    "        # for iteration in tqdm.tqdm(range(VOCABULARY_LIMIT)):\n",
    "            input_tensor, target_tensor = dataset[iteration]\n",
    "        # for iteration, (input_tensor, target_tensor) in enumerate(dataset):\n",
    "            loss = trainer.train(input_tensor, target_tensor, criterion)\n",
    "            total_loss += loss\n",
    "\n",
    "            # if iteration % print_every == 0:\n",
    "            #     print(f'Epoch: {epoch} Iteration: {iteration + 1} loss: {loss}')\n",
    "            #     print(f'Average loss: {total_loss / (iteration + 1)}')\n",
    "        \n",
    "        # print(f'Epoch {epoch} average loss: {total_loss / (iteration + 1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(MAX_LENGTH, HIDDEN_SIZE)\n",
    "decoder = DecoderRNN(HIDDEN_SIZE, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TranscriptionDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with epochs=1000, TEACHER_FORCING_RATIO=0.5, LEARNING_RATE=0.01, HIDDEN_SIZE=256, VOCABULARY_LIMIT=1000\n"
     ]
    }
   ],
   "source": [
    "train_loop(encoder, decoder, dataset, epochs=1000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), f'models/encoder{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}-{VOCABULARY_LIMIT}.pt')\n",
    "torch.save(decoder.state_dict(), f'models/decoder{datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")}-{VOCABULARY_LIMIT}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.load_state_dict(torch.load('models/encoder20230510-205652-10000.pt'))\n",
    "decoder.load_state_dict(torch.load('models/decoder20230510-205652-10000.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = pd.read_csv('data/word-based/word_to_id.csv')\n",
    "tensor_to_word_mapping = {item[1]: item[0] for item in word_to_id.iloc}\n",
    "tensor_to_word_mapping[EOS_TOKEN] = ''\n",
    "\n",
    "transcription_to_id = pd.read_csv('data/word-based/transcription_to_id.csv')\n",
    "transcription_to_id_mapping = {item[1]: item[0] for item in transcription_to_id.iloc}\n",
    "transcription_to_id_mapping[EOS_TOKEN] = ''\n",
    "\n",
    "def tensor_to_word(tensor: Tensor) -> str:\n",
    "    return ''.join(tensor_to_word_mapping[i.item()] for i in tensor)\n",
    "\n",
    "def tensor_to_transcription(tensor: Tensor) -> str:\n",
    "    return ''.join(transcription_to_id_mapping[i.item()] for i in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, input_tensor, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.init_hidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_TOKEN]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_TOKEN:\n",
    "                decoded_words.append(EOS_TOKEN)\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(topi.item())\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(target: Tensor, result: Tensor) -> float:\n",
    "    hit = 0\n",
    "    for i in range(min(len(target), len(result))):\n",
    "        if target[i] == result[i]:\n",
    "            hit += 1\n",
    "\n",
    "    return hit / max(len(target), len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(word1, word2):\n",
    "    m = len(word1)\n",
    "    n = len(word2)\n",
    "\n",
    "    # Create a matrix to store the edit distances\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "    # Fill in the first row and column\n",
    "    for i in range(m + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(n + 1):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    # Calculate the edit distance\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if word1[i - 1] == word2[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(dp[i - 1][j],      # Deletion\n",
    "                                   dp[i][j - 1],      # Insertion\n",
    "                                   dp[i - 1][j - 1])  # Substitution\n",
    "\n",
    "    # Return the edit distance\n",
    "    return dp[m][n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_accuracy(encoder, decoder, dataset):\n",
    "    total_accuracy = 0\n",
    "    amount_of_words = int(2 * VOCABULARY_LIMIT / 8)\n",
    "\n",
    "    for i in range(VOCABULARY_LIMIT, VOCABULARY_LIMIT + amount_of_words):\n",
    "    # for i in range(0, 1):\n",
    "        input_tensor = dataset[i][0]\n",
    "        target_tensor = dataset[i][1]\n",
    "        result_tensor = evaluate(encoder, decoder, input_tensor)\n",
    "\n",
    "        input_word = tensor_to_word(input_tensor.view(-1))\n",
    "        target_word = tensor_to_transcription(target_tensor.view(-1))\n",
    "        result_word = tensor_to_transcription(torch.tensor(result_tensor))\n",
    "\n",
    "        pair_accuracy = accuracy(target_tensor, result_tensor)\n",
    "        total_accuracy += pair_accuracy\n",
    "        \n",
    "        # print(f'Input tensor: {input_tensor}, Target tensor: {target_tensor}, Result tensor: {result_tensor}')\n",
    "        # print(f'Input: {input_word}, Target: {target_word}, Result: {result_word}, Accuracy: {pair_accuracy}')\n",
    "\n",
    "\n",
    "    return total_accuracy / amount_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_model_performance(encoder, decoder, dataset, criterion, is_showing_output=False, runs=1):\n",
    "    total_criterion = 0\n",
    "    amount_of_words = int(2 * VOCABULARY_LIMIT / 8)\n",
    "    for run in range(runs):\n",
    "\n",
    "        for i in range(VOCABULARY_LIMIT, VOCABULARY_LIMIT + amount_of_words):\n",
    "        # for i in range(0, 1):\n",
    "            input_tensor = dataset[i][0]\n",
    "            target_tensor = dataset[i][1]\n",
    "            result_tensor = evaluate(encoder, decoder, input_tensor)\n",
    "\n",
    "            input_word = tensor_to_word(input_tensor.view(-1))\n",
    "            target_word = tensor_to_transcription(target_tensor.view(-1))\n",
    "            result_word = tensor_to_transcription(torch.tensor(result_tensor))\n",
    "\n",
    "            pair_criterion = criterion(target_tensor, result_tensor)\n",
    "            total_criterion += pair_criterion\n",
    "            \n",
    "            if is_showing_output:\n",
    "                # print(f'Input tensor: {input_tensor}, Target tensor: {target_tensor}, Result tensor: {result_tensor}')\n",
    "                print(f'Input: {input_word}, Target: {target_word}, Result: {result_word}, Criterion: {pair_criterion}')\n",
    "\n",
    "\n",
    "    return total_criterion / amount_of_words / runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_model_performance(encoder, decoder, dataset, edit_distance, runs=1, is_showing_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [100, 1000]\n",
    "\n",
    "for epoch in epochs:\n",
    "    print(f'Running for {epoch} epochs')\n",
    "    encoder = EncoderRNN(MAX_LENGTH, HIDDEN_SIZE, device=device)\n",
    "    decoder = DecoderRNN(HIDDEN_SIZE, MAX_LENGTH, device=device)\n",
    "\n",
    "    train_loop(encoder, decoder, dataset, epochs=epoch, print_every=10000)\n",
    "\n",
    "    current_accuracy = calculate_accuracy(encoder, decoder, dataset)\n",
    "\n",
    "    print(f'Epochs: {epoch}, Accuracy: {current_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_encoder_only(input_tensor):\n",
    "    with torch.no_grad():\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.init_hidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(MAX_LENGTH, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "            \n",
    "        return encoder_hidden\n",
    "\n",
    "def calculate_cosine_between_two_vectors(input1, input2):\n",
    "    output1 = run_encoder_only(input1).reshape(HIDDEN_SIZE).cpu().numpy()\n",
    "    output2 = run_encoder_only(input2).reshape(HIDDEN_SIZE).cpu().numpy()\n",
    "\n",
    "    return cosine(output1, output2)\n",
    "\n",
    "def cartesian_product_with_function_as_dataframe(list1, list2, f):\n",
    "    result = [(tensor_to_word(x), tensor_to_word(y), f(x, y)) for x, y in product(list1, list2)]\n",
    "    return pd.DataFrame(result, columns=['Word 1', 'Word 2', 'Result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>конфликтност</td>\n",
       "      <td>конфликтност</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>конфликтност</td>\n",
       "      <td>Кремена</td>\n",
       "      <td>1.012918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>конфликтност</td>\n",
       "      <td>оперно-театрален</td>\n",
       "      <td>0.882621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Кремена</td>\n",
       "      <td>конфликтност</td>\n",
       "      <td>1.012918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Кремена</td>\n",
       "      <td>Кремена</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Кремена</td>\n",
       "      <td>оперно-театрален</td>\n",
       "      <td>0.265607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>оперно-театрален</td>\n",
       "      <td>конфликтност</td>\n",
       "      <td>0.882621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>оперно-театрален</td>\n",
       "      <td>Кремена</td>\n",
       "      <td>0.265607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>оперно-театрален</td>\n",
       "      <td>оперно-театрален</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word 1            Word 2    Result\n",
       "0      конфликтност      конфликтност  0.000000\n",
       "1      конфликтност           Кремена  1.012918\n",
       "2      конфликтност  оперно-театрален  0.882621\n",
       "3           Кремена      конфликтност  1.012918\n",
       "4           Кремена           Кремена  0.000000\n",
       "5           Кремена  оперно-театрален  0.265607\n",
       "6  оперно-театрален      конфликтност  0.882621\n",
       "7  оперно-театрален           Кремена  0.265607\n",
       "8  оперно-театрален  оперно-театрален  0.000000"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words = [dataset[i][0] for i in range(VOCABULARY_LIMIT, VOCABULARY_LIMIT + 10)]\n",
    "words = [dataset[i][0] for i in range(26691, 26694)]\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "\n",
    "cartesian_product_with_function_as_dataframe(words, words, calculate_cosine_between_two_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9690224c8ba08809808eb1dea2a550f7a1d7415f0de077dd69f40462bd6d7bb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
