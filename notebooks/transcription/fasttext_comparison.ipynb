{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cc.bg.300.bin'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import fasttext.util\n",
    "fasttext.util.download_model('bg', if_exists='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "ft = fasttext.load_model('cc.bg.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __cosine_similarity(a: np.ndarray, b: np.ndarray):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def cosine_similarity(word1: str, word2: str):\n",
    "    a = ft.get_word_vector(word1)\n",
    "    b = ft.get_word_vector(word2)\n",
    "\n",
    "    longer_word_length = max(a.shape[0], b.shape[0])\n",
    "    shorter_word_length = min(a.shape[0], b.shape[0])\n",
    "    similarities = sum(__cosine_similarity(a[i], b[i]) for i in range(shorter_word_length))\n",
    "\n",
    "    return similarities / shorter_word_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/d/Projects/masters-thesis/data/paronym.txt') as file_pointer:\n",
    "    lines = file_pointer.readlines()\n",
    "\n",
    "lines = [line.strip().split(',') for line in lines]\n",
    "lines = [(word1.strip(), word2.strip(), c.strip()) for word1, word2, c in lines]\n",
    "train_test_split_index = int(0.8 * len(lines))\n",
    "\n",
    "train_lines = lines[:train_test_split_index]\n",
    "test_lines = lines[train_test_split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyubolp/detecting-loanwords/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "train_input = [(cosine_similarity(word1, word2), is_paronym) for word1, word2, is_paronym in train_lines]\n",
    "\n",
    "X = np.array([result for result, _ in train_input]).reshape(-1, 1)\n",
    "y = np.array([int(is_paronym) for _, is_paronym in train_input]).reshape(-1, 1)\n",
    "\n",
    "reg = LogisticRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = [(cosine_similarity(word1, word2), is_paronym) for word1, word2, is_paronym in test_lines]\n",
    "\n",
    "X = np.array([result for result, _ in test_input]).reshape(-1, 1)\n",
    "actual = np.array([int(is_paronym) for _, is_paronym in test_input]).reshape(-1, 1)\n",
    "predicted = reg.predict(X)\n",
    "\n",
    "results = list(zip(actual, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tp=15, tn=18, fp=1, fn=3, ap=18, an=19, pp=16, pn=21'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = sum(1 for a, p in results if a == p and a == 1)\n",
    "tn = sum(1 for a, p in results if a == p and a == 0)\n",
    "fp = sum(1 for a, p in results if a != p and a == 0)\n",
    "fn = sum(1 for a, p in results if a != p and a == 1)\n",
    "\n",
    "ap = sum(1 for a, _ in results if a == 1)\n",
    "an = sum(1 for a, _ in results if a == 0)\n",
    "\n",
    "pp = sum(1 for _, p in results if p == 1)\n",
    "pn = sum(1 for _, p in results if p == 0)\n",
    "\n",
    "f'{tp=}, {tn=}, {fp=}, {fn=}, {ap=}, {an=}, {pp=}, {pn=}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accuracy=0.892, precision=0.938 recall=0.833, f1=0.882'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (tp + tn) / (ap + an)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / ap\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "f'{accuracy=:.3f}, {precision=:.3f} {recall=:.3f}, {f1=:.3f}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
