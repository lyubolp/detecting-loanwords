{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_paths = [\n",
    "    '/mnt/d/Projects/masters-thesis/data/books/a5/42466',\n",
    "    '/mnt/d/Projects/masters-thesis/data/books/28/10479',\n",
    "    '/mnt/d/Projects/masters-thesis/data/books/00/19',\n",
    "    '/mnt/d/Projects/masters-thesis/data/books/63/25456',\n",
    "    '/mnt/d/Projects/masters-thesis/data/books/25/9703'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences_from_book(book_path: str) -> list[str]:\n",
    "    with open(book_path, 'r') as file_descriptor:\n",
    "        lines = file_descriptor.readlines()\n",
    "        lines = [line.strip() for line in lines]\n",
    "        lines = [line for line in lines if line != '']\n",
    "\n",
    "        sentences = sum([sent_tokenize(line) for line in lines], [])\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "\n",
    "formatting_symbols = ['E>', 'E$', 'D>', 'D$', '@', 'C>', 'C$', 'P>', 'P$', \n",
    "                      'S>', 'S$', '\\t', '|', '>', '#']\n",
    "\n",
    "def cleanup_formatting(sentence: str) -> str:\n",
    "    for symbol in formatting_symbols:\n",
    "        while symbol in sentence:\n",
    "            sentence = sentence.replace(symbol, '')\n",
    "    return sentence\n",
    "\n",
    "def tokenize_sentence(sentence: str) -> list[str]:\n",
    "    \n",
    "    sentence = sentence.lower()\n",
    "    tokenized = word_tokenize(sentence)\n",
    "\n",
    "    return tokenized\n",
    "\n",
    "def parse_book(book_path: str) -> set[str]:\n",
    "    sentences = get_sentences_from_book(book_path)\n",
    "    sentences = [cleanup_formatting(sentence) for sentence in sentences]\n",
    "    words = [tokenize_sentence(sentence) for sentence in sentences if sentence != '']\n",
    "\n",
    "    words = sum(words, [])\n",
    "    words = [word.lower() for word in words]\n",
    "    return set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = set()\n",
    "for book_path in book_paths[:1]:\n",
    "    words = words | parse_book(book_path)\n",
    "\n",
    "words = set(list(words)[:5000])\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>дума</th>\n",
       "      <th>произход</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>откакто</td>\n",
       "      <td>bg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>категорична</td>\n",
       "      <td>bg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>наново</td>\n",
       "      <td>bg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>гадно</td>\n",
       "      <td>bg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gtx</td>\n",
       "      <td>bg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>платна</td>\n",
       "      <td>bg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>светльо</td>\n",
       "      <td>bg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>люлееш</td>\n",
       "      <td>bg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>приблизително</td>\n",
       "      <td>bg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>дистанция</td>\n",
       "      <td>bg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               дума произход\n",
       "0           откакто       bg\n",
       "1       категорична       bg\n",
       "2            наново       bg\n",
       "3             гадно       bg\n",
       "4               gtx       bg\n",
       "...             ...      ...\n",
       "4995         платна       bg\n",
       "4996        светльо       bg\n",
       "4997         люлееш       bg\n",
       "4998  приблизително       bg\n",
       "4999      дистанция       bg\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(words, columns=['дума'])\n",
    "df['произход'] = 'bg'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loanwords = pd.read_csv('/mnt/d/Projects/masters-thesis/data/loanwords_only.csv')\n",
    "\n",
    "loanwords = pd.concat([loanwords, df])\n",
    "loanwords = loanwords.dropna()\n",
    "\n",
    "loanwords.to_csv('/mnt/d/Projects/masters-thesis/data/loanwords_5k_bg_words.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
