{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_paths = [\n",
    "    '/mnt/d/Projects/masters-thesis/data/books/a5/42466',\n",
    "    '/mnt/d/Projects/masters-thesis/data/books/28/10479',\n",
    "    '/mnt/d/Projects/masters-thesis/data/books/00/19',\n",
    "    '/mnt/d/Projects/masters-thesis/data/books/63/25456',\n",
    "    '/mnt/d/Projects/masters-thesis/data/books/25/9703'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences_from_book(book_path: str) -> list[str]:\n",
    "    with open(book_path, 'r') as file_descriptor:\n",
    "        lines = file_descriptor.readlines()\n",
    "        lines = [line.strip() for line in lines]\n",
    "        lines = [line for line in lines if line != '']\n",
    "\n",
    "        sentences = sum([sent_tokenize(line) for line in lines], [])\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "\n",
    "formatting_symbols = ['E>', 'E$', 'D>', 'D$', '@', 'C>', 'C$', 'P>', 'P$', \n",
    "                      'S>', 'S$', '\\t', '|', '>', '#']\n",
    "\n",
    "def cleanup_formatting(sentence: str) -> str:\n",
    "    for symbol in formatting_symbols:\n",
    "        while symbol in sentence:\n",
    "            sentence = sentence.replace(symbol, '')\n",
    "    return sentence\n",
    "\n",
    "def tokenize_sentence(sentence: str) -> list[str]:\n",
    "    \n",
    "    sentence = sentence.lower()\n",
    "    tokenized = word_tokenize(sentence)\n",
    "\n",
    "    return tokenized\n",
    "\n",
    "def parse_book(book_path: str) -> set[str]:\n",
    "    sentences = get_sentences_from_book(book_path)\n",
    "    sentences = [cleanup_formatting(sentence) for sentence in sentences]\n",
    "    words = [tokenize_sentence(sentence) for sentence in sentences if sentence != '']\n",
    "\n",
    "    words = sum(words, [])\n",
    "    words = [word.lower() for word in words]\n",
    "    return set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13936"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = set()\n",
    "for book_path in book_paths[:1]:\n",
    "    words = words | parse_book(book_path)\n",
    "\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>дума</th>\n",
       "      <th>произход</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>показват</td>\n",
       "      <td>bg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>бебешка</td>\n",
       "      <td>bg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>проговоря</td>\n",
       "      <td>bg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>случаен</td>\n",
       "      <td>bg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>потопят</td>\n",
       "      <td>bg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13931</th>\n",
       "      <td>зн…</td>\n",
       "      <td>bg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13932</th>\n",
       "      <td>спрял</td>\n",
       "      <td>bg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13933</th>\n",
       "      <td>забили</td>\n",
       "      <td>bg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13934</th>\n",
       "      <td>дългичко</td>\n",
       "      <td>bg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13935</th>\n",
       "      <td>консултирам</td>\n",
       "      <td>bg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13936 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              дума произход\n",
       "0         показват       bg\n",
       "1          бебешка       bg\n",
       "2        проговоря       bg\n",
       "3          случаен       bg\n",
       "4          потопят       bg\n",
       "...            ...      ...\n",
       "13931          зн…       bg\n",
       "13932        спрял       bg\n",
       "13933       забили       bg\n",
       "13934     дългичко       bg\n",
       "13935  консултирам       bg\n",
       "\n",
       "[13936 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(words, columns=['дума'])\n",
    "df['произход'] = 'bg'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loanwords = pd.read_csv('/mnt/d/Projects/masters-thesis/data/loanwords_only.csv')\n",
    "\n",
    "loanwords = pd.concat([loanwords, df])\n",
    "loanwords = loanwords.dropna()\n",
    "\n",
    "loanwords.to_csv('/mnt/d/Projects/masters-thesis/data/loanwords_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loanwords = pd.read_csv('/mnt/d/Projects/masters-thesis/data/loanwords.csv')\n",
    "del loanwords[loanwords.columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loanwords.to_csv('/mnt/d/Projects/masters-thesis/data/loanwords_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
