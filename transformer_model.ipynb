{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "import os\n",
    "\n",
    "from copy import deepcopy\n",
    "from typing import Iterable, List\n",
    "\n",
    "# Third party imports\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "\n",
    "# Local application imports\n",
    "import src.constants as const\n",
    "from src.dataset_utils import yield_tokens, sentence_to_tensor, load_files, build_vocab_transformation\n",
    "from src.transcription_dataset import TranscriptionDataset\n",
    "from src.syllable_splitter import split_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Брой файлове: 47825, брой редове: 80615534'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all the files\n",
    "files = load_files('/mnt/d/Projects/masters-thesis/data/transcriptions')\n",
    "\n",
    "filepaths_to_size = pd.read_csv('/mnt/d/Projects/masters-thesis/data/filepath_to_size.csv')\n",
    "lines_count = filepaths_to_size['size'].sum()\n",
    "\n",
    "f'Брой файлове: {len(files)}, брой редове: {lines_count}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & test split\n",
    "sentences_to_use = 50000\n",
    "train_split = int(const.TRAIN_TEST_SPLIT * sentences_to_use)\n",
    "validation_split = int((const.TRAIN_TEST_SPLIT + const.TRAIN_VALIDATION_SPLIT) * sentences_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TranscriptionDataset(files, start_index=0, end_index=train_split)\n",
    "validation_dataset = TranscriptionDataset(files, start_index=train_split, end_index=validation_split)\n",
    "test_dataset = TranscriptionDataset(files, start_index=validation_split, end_index=sentences_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ln in [const.SRC_LANGUAGE, const.TGT_LANGUAGE]:\n",
    "    # Create torchtext's Vocab object\n",
    "    const.vocab_transform[ln] = build_vocab_transformation(train_dataset, ln)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes 229 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([const.BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([const.EOS_IDX])))\n",
    "\n",
    "\n",
    "text_transform_src = sequential_transforms(word_tokenize, #Tokenization\n",
    "                                                # lambda x: sum([split_word(word) for word in x], []), #Syllable splitting\n",
    "                                                const.vocab_transform[const.SRC_LANGUAGE], #Numericalization\n",
    "                                                tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "vowels_transcription = ['a', 'ʌ', 'ɤ̞',  'ɐ', 'ɔ', 'o', 'u', 'ɛ', 'i']\n",
    "text_transform_tgt = sequential_transforms(word_tokenize, #Tokenization\n",
    "                                                # lambda x: [split_word(word, vowels_transcription) for word in x], #Syllable splitting\n",
    "                                                const.vocab_transform[const.TGT_LANGUAGE], #Numericalization\n",
    "                                                tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "# function to collate data samples into batch tensors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform_src(src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform_tgt(tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=const.PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=const.PAD_IDX)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['плъз',\n",
       " 'на',\n",
       " 'ха',\n",
       " 'слу',\n",
       " 'хо',\n",
       " 'ве',\n",
       " 'за',\n",
       " 'про',\n",
       " 'ро',\n",
       " 'чес',\n",
       " 'тво',\n",
       " 'спо',\n",
       " 'ред',\n",
       " 'ко',\n",
       " 'е',\n",
       " 'то',\n",
       " 'мно',\n",
       " 'го',\n",
       " 'ско',\n",
       " 'ро',\n",
       " 'на',\n",
       " 'прес',\n",
       " 'то',\n",
       " 'ла',\n",
       " 'в',\n",
       " 'за',\n",
       " 'ла',\n",
       " 'та',\n",
       " 'на',\n",
       " 'кра',\n",
       " 'ле',\n",
       " 'те',\n",
       " 'на',\n",
       " 'ри',\n",
       " 'ва',\n",
       " 'ще',\n",
       " 'сед',\n",
       " 'не',\n",
       " 'крал',\n",
       " ',',\n",
       " 'кой',\n",
       " 'то',\n",
       " 'е',\n",
       " 'ис',\n",
       " 'тин',\n",
       " 'ски',\n",
       " 'по',\n",
       " 'то',\n",
       " 'мък',\n",
       " 'на',\n",
       " 'ри',\n",
       " 'ва',\n",
       " '.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src, tgt = train_dataset[123]\n",
    "\n",
    "\n",
    "transforms = [word_tokenize,\n",
    "              lambda x: sum([split_word(word) for word in x], []),\n",
    "              # const.vocab_transform[const.SRC_LANGUAGE],\n",
    "              # tensor_transform\n",
    "              ]\n",
    "\n",
    "\n",
    "for transform in transforms:\n",
    "    src = transform(src)\n",
    "\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(deepcopy(train_dataset), batch_size=128, collate_fn=collate_fn)\n",
    "validation_dataloader = DataLoader(deepcopy(validation_dataset), batch_size=128, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(deepcopy(test_dataset), batch_size=128, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "\n",
    "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# Seq2Seq Network\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=const.device)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=const.device).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == const.PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == const.PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = len(const.vocab_transform[const.SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(const.vocab_transform[const.TGT_LANGUAGE])\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(const.device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=const.PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_epoch(model, optimizer, train_dataloader):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "\n",
    "    for src, tgt in train_dataloader:\n",
    "        src = src.to(const.device)\n",
    "        tgt = tgt.to(const.device)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(train_dataloader))\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    for src, tgt in validation_dataloader:\n",
    "        src = src.to(const.device)\n",
    "        tgt = tgt.to(const.device)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(validation_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, NUM_EPOCHS\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m      5\u001b[0m     start_time \u001b[39m=\u001b[39m timer()\n\u001b[0;32m----> 6\u001b[0m     train_loss \u001b[39m=\u001b[39m train_epoch(transformer, optimizer, train_dataloader)\n\u001b[1;32m      7\u001b[0m     end_time \u001b[39m=\u001b[39m timer()\n\u001b[1;32m      8\u001b[0m     val_loss \u001b[39m=\u001b[39m evaluate(transformer)\n",
      "Cell \u001b[0;32mIn[12], line 21\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, train_dataloader)\u001b[0m\n\u001b[1;32m     19\u001b[0m tgt_out \u001b[39m=\u001b[39m tgt[\u001b[39m1\u001b[39m:, :]\n\u001b[1;32m     20\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(logits\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, logits\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]), tgt_out\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m---> 21\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     23\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     24\u001b[0m losses \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/detecting-loanwords/.venv/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/detecting-loanwords/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 25\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer, train_dataloader)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer)\n",
    "    print(f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "torch.save(transformer.state_dict(), f'models/transformer-{today_date}-{sentences_to_use}-{NUM_EPOCHS}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.load_state_dict(torch.load('models/transformer-2023-09-11-50000-25.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transform = {}\n",
    "for ln in [const.SRC_LANGUAGE, const.TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(word_tokenize, #Tokenization\n",
    "                                               const.vocab_transform[ln], #Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(const.device)\n",
    "    src_mask = src_mask.to(const.device)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(const.device)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(const.device)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(const.device)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == const.EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    src_sentence = src_sentence.lower()\n",
    "    model.eval()\n",
    "    src = text_transform[const.SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=const.BOS_IDX).flatten()\n",
    "    # print(list(tgt_tokens.cpu().numpy()))\n",
    "    return \" \".join(const.vocab_transform[const.TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — , kʌk stɛ ? \n",
      " dobrɛ sɐm , blʌgodʌrjɐ . \n",
      " i i \n",
      " i ɛzik \n",
      " ɛzik i ɛzik \n",
      " ljɐtoto ɛ moɛto i vrɛmɛ nʌ godinʌtʌ . \n",
      " v i i , si . \n",
      " , i doʃʌtʌ mi slɛd dɐlɐg i dɛn . \n",
      " . \n",
      " , nʌ . i i i i i . \n"
     ]
    }
   ],
   "source": [
    "print(translate(transformer, \"здравей, как сте?\"))\n",
    "print(translate(transformer, \"Добре съм, благодаря.\"))\n",
    "print(translate(transformer, \"Айрян айрян\"))\n",
    "print(translate(transformer, \"Български език\"))\n",
    "print(translate(transformer, \"език Български език\"))\n",
    "print(translate(transformer, \"Лятото е моето любимо време на годината.\"))\n",
    "print(translate(transformer, \"В парка разцъфтяха невероятни цветя.\"))\n",
    "print(translate(transformer, \"Музиката успокоява душата ми след дълъг работен ден.\"))\n",
    "print(translate(transformer, \"Вчера се срещнах със стар приятел, когото не бях виждал години.\"))\n",
    "print(translate(transformer, \"Четенето на книги разширява хоризонтите и обогатява речника.\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
