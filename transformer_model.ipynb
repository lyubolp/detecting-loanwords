{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "import os\n",
    "\n",
    "from copy import deepcopy\n",
    "from typing import Iterable, List\n",
    "\n",
    "# Third party imports\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "\n",
    "# Local application imports\n",
    "import src.constants as const\n",
    "from src.dataset_utils import yield_tokens, sentence_to_tensor, load_files, build_vocab_transformation, tokenize_source, tokenize_target\n",
    "from src.transcription_dataset import TranscriptionDataset\n",
    "from src.syllable_splitter import split_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Брой файлове: 47825, брой редове: 80615534'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all the files\n",
    "files = load_files('/mnt/d/Projects/masters-thesis/data/transcriptions')\n",
    "\n",
    "filepaths_to_size = pd.read_csv('/mnt/d/Projects/masters-thesis/data/filepath_to_size.csv')\n",
    "lines_count = filepaths_to_size['size'].sum()\n",
    "\n",
    "f'Брой файлове: {len(files)}, брой редове: {lines_count}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & test split\n",
    "sentences_to_use = 50000\n",
    "train_split = int(const.TRAIN_TEST_SPLIT * sentences_to_use)\n",
    "validation_split = int((const.TRAIN_TEST_SPLIT + const.TRAIN_VALIDATION_SPLIT) * sentences_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TranscriptionDataset(files, tokenization_src=tokenize_source, tokenization_tgt=tokenize_target,\n",
    "                                     start_index=0, end_index=train_split)\n",
    "validation_dataset = TranscriptionDataset(files, tokenization_src=tokenize_source, tokenization_tgt=tokenize_target,\n",
    "                                          start_index=train_split, end_index=validation_split)\n",
    "test_dataset = TranscriptionDataset(files, tokenization_src=tokenize_source, tokenization_tgt=tokenize_target,\n",
    "                                    start_index=validation_split, end_index=sentences_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ln in [const.SRC_LANGUAGE, const.TGT_LANGUAGE]:\n",
    "    # Create torchtext's Vocab object\n",
    "    const.vocab_transform[ln] = build_vocab_transformation(train_dataset, ln)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes 229 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([const.BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([const.EOS_IDX])))\n",
    "\n",
    "\n",
    "text_transform_src = sequential_transforms(const.vocab_transform[const.SRC_LANGUAGE], #Numericalization\n",
    "                                                tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "vowels_transcription = ['a', 'ʌ', 'ɤ̞',  'ɐ', 'ɔ', 'o', 'u', 'ɛ', 'i']\n",
    "text_transform_tgt = sequential_transforms(const.vocab_transform[const.TGT_LANGUAGE], #Numericalization\n",
    "                                                tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "# function to collate data samples into batch tensors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform_src(src_sample))\n",
    "        tgt_batch.append(text_transform_tgt(tgt_sample))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=const.PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=const.PAD_IDX)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(deepcopy(train_dataset), batch_size=128, collate_fn=collate_fn)\n",
    "validation_dataloader = DataLoader(deepcopy(validation_dataset), batch_size=128, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(deepcopy(test_dataset), batch_size=128, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "\n",
    "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# Seq2Seq Network\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=const.device)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=const.device).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == const.PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == const.PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = len(const.vocab_transform[const.SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(const.vocab_transform[const.TGT_LANGUAGE])\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(const.device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=const.PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_epoch(model, optimizer, train_dataloader):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "\n",
    "    for src, tgt in train_dataloader:\n",
    "        src = src.to(const.device)\n",
    "        tgt = tgt.to(const.device)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(train_dataloader))\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    for src, tgt in validation_dataloader:\n",
    "        src = src.to(const.device)\n",
    "        tgt = tgt.to(const.device)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(validation_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 4.714, Val loss: 2.977, Epoch time = 531.922s\n",
      "Epoch: 2, Train loss: 2.111, Val loss: 1.263, Epoch time = 522.123s\n",
      "Epoch: 3, Train loss: 0.973, Val loss: 0.654, Epoch time = 519.233s\n",
      "Epoch: 4, Train loss: 0.531, Val loss: 0.399, Epoch time = 519.653s\n",
      "Epoch: 5, Train loss: 0.343, Val loss: 0.290, Epoch time = 513.225s\n",
      "Epoch: 6, Train loss: 0.240, Val loss: 0.207, Epoch time = 513.179s\n",
      "Epoch: 7, Train loss: 0.184, Val loss: 0.161, Epoch time = 511.824s\n",
      "Epoch: 8, Train loss: 0.137, Val loss: 0.159, Epoch time = 511.727s\n",
      "Epoch: 9, Train loss: 0.110, Val loss: 0.103, Epoch time = 511.984s\n",
      "Epoch: 10, Train loss: 0.088, Val loss: 0.091, Epoch time = 511.831s\n",
      "Epoch: 11, Train loss: 0.074, Val loss: 0.115, Epoch time = 511.824s\n",
      "Epoch: 12, Train loss: 0.060, Val loss: 0.115, Epoch time = 511.754s\n",
      "Epoch: 13, Train loss: 0.050, Val loss: 0.071, Epoch time = 511.510s\n",
      "Epoch: 14, Train loss: 0.041, Val loss: 0.060, Epoch time = 511.865s\n",
      "Epoch: 15, Train loss: 0.034, Val loss: 0.058, Epoch time = 511.707s\n",
      "Epoch: 16, Train loss: 0.029, Val loss: 0.064, Epoch time = 511.780s\n",
      "Epoch: 17, Train loss: 0.025, Val loss: 0.057, Epoch time = 511.949s\n",
      "Epoch: 18, Train loss: 0.022, Val loss: 0.058, Epoch time = 511.895s\n",
      "Epoch: 19, Train loss: 0.020, Val loss: 0.053, Epoch time = 511.768s\n",
      "Epoch: 20, Train loss: 0.017, Val loss: 0.062, Epoch time = 511.903s\n",
      "Epoch: 21, Train loss: 0.015, Val loss: 0.047, Epoch time = 511.982s\n",
      "Epoch: 22, Train loss: 0.014, Val loss: 0.041, Epoch time = 511.464s\n",
      "Epoch: 23, Train loss: 0.012, Val loss: 0.042, Epoch time = 511.714s\n",
      "Epoch: 24, Train loss: 0.011, Val loss: 0.039, Epoch time = 511.606s\n",
      "Epoch: 25, Train loss: 0.010, Val loss: 0.039, Epoch time = 511.450s\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 25\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer, train_dataloader)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer)\n",
    "    print(f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NUM_EPOCHS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatetime\u001b[39;00m \u001b[39mimport\u001b[39;00m datetime\n\u001b[1;32m      2\u001b[0m today_date \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mtoday()\u001b[39m.\u001b[39mstrftime(\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m torch\u001b[39m.\u001b[39msave(transformer\u001b[39m.\u001b[39mstate_dict(), \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodels/transformer-\u001b[39m\u001b[39m{\u001b[39;00mtoday_date\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00msentences_to_use\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00mNUM_EPOCHS\u001b[39m}\u001b[39;00m\u001b[39m.pth\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NUM_EPOCHS' is not defined"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "torch.save(transformer.state_dict(), f'models/transformer-{today_date}-{sentences_to_use}-{NUM_EPOCHS}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.load_state_dict(torch.load('models/transformer-2023-10-08-50000-25.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transform_src = sequential_transforms(tokenize_source,\n",
    "    const.vocab_transform[const.SRC_LANGUAGE], #Numericalization\n",
    "                                                tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "vowels_transcription = ['a', 'ʌ', 'ɤ̞',  'ɐ', 'ɔ', 'o', 'u', 'ɛ', 'i']\n",
    "text_transform_tgt = sequential_transforms(const.vocab_transform[const.TGT_LANGUAGE], #Numericalization\n",
    "                                                tensor_transform) # Add BOS/EOS and create tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(const.device)\n",
    "    src_mask = src_mask.to(const.device)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(const.device)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(const.device)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(const.device)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == const.EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    src_sentence = src_sentence.lower()\n",
    "    model.eval()\n",
    "    src = text_transform_src(src_sentence).view(-1, 1)\n",
    "\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=const.BOS_IDX).flatten()\n",
    "    # print(list(tgt_tokens.cpu().numpy()))\n",
    "    return \" \".join(const.vocab_transform[const.TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(model: Seq2SeqTransformer, src_sentence: str):\n",
    "    src_sentence = src_sentence.lower()\n",
    "    model.eval()\n",
    "    src = text_transform_src(src_sentence).view(-1, 1)\n",
    "\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    \n",
    "    embedding = model.encode(src.to(const.device), src_mask.to(const.device))\n",
    "\n",
    "    return (sum(embedding) / len(embedding))[0].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.86730608e-01, -2.35656172e-01,  7.73406446e-01, -7.14438498e-01,\n",
       "        5.65402925e-01, -4.64507461e-01,  1.44616234e+00, -4.89935637e-01,\n",
       "        1.72372341e-01,  2.52599269e-01, -9.74091142e-03, -8.65800440e-01,\n",
       "        1.16328061e+00,  4.54129070e-01, -5.86373731e-02, -1.45054221e-01,\n",
       "        1.09022903e+00,  1.32008195e+00,  9.76748645e-01,  1.06411362e+00,\n",
       "       -4.79722694e-02, -6.20427608e-01, -6.62277937e-01, -3.72619331e-01,\n",
       "       -1.25096798e-01,  2.52738625e-01, -1.01383552e-01,  5.44131875e-01,\n",
       "        4.70921546e-01,  8.83736730e-01,  6.61719263e-01,  2.00718999e-01,\n",
       "        3.51873428e-01,  6.74048126e-01,  1.30980122e+00,  2.00965953e+00,\n",
       "        9.68718946e-01,  1.01932120e+00, -7.86230922e-01,  1.60880029e+00,\n",
       "        8.97166133e-01,  2.54523730e+00, -7.75524676e-01,  1.23724604e+00,\n",
       "       -2.24674940e-02,  4.63824689e-01,  5.52128255e-03,  1.89576530e+00,\n",
       "       -1.31445563e+00,  8.89696121e-01, -1.07214665e+00,  1.32594407e+00,\n",
       "       -4.94223237e-01,  1.54838562e+00, -1.23859972e-01,  1.25638628e+00,\n",
       "        3.18066061e-01,  1.40631700e+00, -5.51911533e-01,  1.94595265e+00,\n",
       "       -6.93055868e-01,  1.00342584e+00, -1.04734755e+00,  8.97907555e-01,\n",
       "       -2.65234143e-01,  1.52759039e+00,  2.54592579e-02,  6.77615225e-01,\n",
       "        3.50639582e-01,  5.72897792e-01, -5.79573870e-01,  6.73609436e-01,\n",
       "       -8.02058458e-01,  1.41516304e+00, -5.58097601e-01,  7.68858194e-01,\n",
       "       -2.01588511e+00,  1.37202740e+00, -1.18891263e+00,  1.84946263e+00,\n",
       "        6.86980367e-01, -3.18172216e-01, -6.73216581e-02, -1.76610029e+00,\n",
       "        2.92876840e-01,  7.69987181e-02, -3.95681053e-01,  1.33276373e-01,\n",
       "       -7.10651875e-02, -5.17189741e-01, -1.43889761e+00,  9.43415761e-02,\n",
       "       -8.64242464e-02, -9.48579311e-01,  6.19422555e-01,  2.78496057e-01,\n",
       "        7.24774182e-01,  1.24673665e-01,  6.21982157e-01, -6.39580607e-01,\n",
       "       -1.02453041e+00,  7.29426980e-01,  6.10764861e-01,  1.17380515e-01,\n",
       "        9.27501559e-01, -1.08186357e-01, -5.57819366e-01,  2.28752136e-01,\n",
       "       -6.79491401e-01, -4.36381638e-01,  2.86788940e-01,  8.19154501e-01,\n",
       "        3.80666882e-01,  1.86591700e-01,  7.54710436e-01,  1.38242692e-02,\n",
       "       -4.04212713e-01,  6.03398442e-01,  7.89829016e-01, -7.33493686e-01,\n",
       "       -9.01130974e-01, -6.11335039e-02, -1.15297973e+00,  1.22500634e+00,\n",
       "        2.14647919e-01,  9.03380096e-01, -4.77994919e-01,  6.36789918e-01,\n",
       "        1.00636280e+00,  8.42887282e-01, -8.21082652e-01, -5.96720338e-01,\n",
       "       -5.64001799e-01, -2.57151335e-01, -8.21799099e-01,  1.28994465e+00,\n",
       "        4.53137964e-01,  1.02369308e+00,  1.11346221e+00,  7.58475780e-01,\n",
       "        8.16657245e-01,  2.98019111e-01, -2.60329768e-02, -5.80508471e-01,\n",
       "        6.70718729e-01,  9.67352271e-01,  1.08344018e+00,  7.09482312e-01,\n",
       "        4.91224289e-01,  1.05272150e+00, -8.75627875e-01, -7.86075950e-01,\n",
       "       -6.11395180e-01, -2.89675951e-01,  7.81983972e-01,  5.97795427e-01,\n",
       "        7.67283738e-01,  1.51079535e-01, -6.96761668e-01,  1.69388843e+00,\n",
       "       -1.67015597e-01, -8.05782676e-02, -6.35451615e-01, -3.17337602e-01,\n",
       "       -1.14955984e-01,  1.66819066e-01,  6.93898499e-02,  2.19376087e+00,\n",
       "       -1.40257955e+00,  1.50877094e+00, -2.93970466e-01, -3.56976300e-01,\n",
       "       -4.17222947e-01,  3.03982437e-01, -1.67561114e-01,  1.40651786e+00,\n",
       "       -9.44521666e-01, -2.39612401e-01,  1.28234088e-01,  2.32865429e+00,\n",
       "       -8.06148291e-01,  9.05117929e-01, -1.03499331e-01,  5.26417315e-01,\n",
       "       -2.07073390e-01,  1.81394279e-01, -5.43384552e-01, -2.29662225e-01,\n",
       "       -4.50182974e-01,  1.40030146e+00, -3.28881919e-01,  8.64325643e-01,\n",
       "       -1.42799568e+00, -2.31264278e-01,  1.46813050e-01,  9.40564051e-02,\n",
       "       -1.48179531e-01,  1.00263603e-01, -5.61328828e-01, -2.41315857e-01,\n",
       "       -1.07399583e+00,  5.65081835e-03,  1.20621167e-01, -6.72028586e-02,\n",
       "       -5.90916634e-01,  6.01314187e-01, -8.43143702e-01,  1.06143188e+00,\n",
       "       -3.12990397e-01,  8.58980417e-01,  1.40353549e+00, -1.07088959e+00,\n",
       "        5.11011839e-01,  1.97307765e-01, -7.30398059e-01, -1.29641056e+00,\n",
       "       -6.09329820e-01,  3.39736044e-01,  6.02718771e-01,  4.34411019e-01,\n",
       "       -1.89067149e+00, -3.11685324e-01, -1.86387852e-01,  1.39871991e+00,\n",
       "       -1.45780355e-01,  1.09806645e+00, -1.54667288e-01,  4.14452404e-02,\n",
       "        1.57907337e-01, -2.50438809e-01,  7.27045119e-01, -3.45293730e-01,\n",
       "       -1.15396023e+00, -2.59477854e-01, -1.17851377e+00,  8.30965757e-01,\n",
       "       -1.08194888e+00,  4.02229667e-01, -1.31668520e+00, -1.41060233e+00,\n",
       "        3.38301241e-01,  6.65323958e-02,  6.85531974e-01,  4.60508049e-01,\n",
       "        1.97957501e-01, -7.36851871e-01,  2.43746072e-01, -3.11079293e-01,\n",
       "       -1.42642832e+00, -3.37208360e-01, -7.16123700e-01, -7.11200684e-02,\n",
       "       -9.25429940e-01,  6.17229521e-01, -1.30416095e+00,  1.89588332e+00,\n",
       "       -7.79733777e-01,  1.16720945e-02, -1.37836188e-01, -1.31238115e+00,\n",
       "       -1.12743413e+00, -3.81464332e-01,  3.90472151e-02,  6.47669435e-01,\n",
       "        1.60945070e+00,  1.93831503e-01, -3.87399644e-01,  3.41325313e-01,\n",
       "        5.21912694e-01, -6.26078069e-01,  1.20770490e+00, -8.83232355e-01,\n",
       "       -1.71813309e-01, -4.02860582e-01,  2.76947141e-01,  5.05304873e-01,\n",
       "       -9.67889309e-01, -1.08535260e-01, -1.49875712e+00,  6.43296003e-01,\n",
       "       -5.60779452e-01, -5.73068023e-01, -7.72845387e-01,  6.11044049e-01,\n",
       "        4.41750705e-01, -8.01942885e-01,  1.01686764e+00,  5.68381310e-01,\n",
       "        5.02897501e-01,  1.05329290e-01,  2.44626105e-02, -2.84634769e-01,\n",
       "       -5.61702132e-01,  4.85276878e-02, -3.90945077e-01,  6.21396184e-01,\n",
       "       -3.90430808e-01, -3.26943874e-01,  9.03029203e-01, -2.09340975e-01,\n",
       "        2.54515201e-01,  1.11930716e+00,  2.73679078e-01,  8.16814005e-02,\n",
       "        9.59876478e-02,  6.11790538e-01, -1.48537719e+00, -5.54773152e-01,\n",
       "        6.47298932e-01, -3.11190616e-02,  2.32465401e-01, -9.15196657e-01,\n",
       "       -1.43454528e+00,  4.52456847e-02,  3.38923931e-02,  2.27575988e-01,\n",
       "       -4.31752205e-01,  2.06403494e-01,  1.70165494e-01, -2.30475619e-01,\n",
       "       -1.03124723e-01,  1.01199493e-01, -1.61860120e+00,  3.49830657e-01,\n",
       "        7.29226828e-01, -3.10442090e-01, -9.54559267e-01, -3.96745652e-01,\n",
       "       -1.26881495e-01, -8.17856908e-01,  4.97653425e-01, -7.45932311e-02,\n",
       "       -4.49358016e-01, -5.17959535e-01, -1.27319908e+00, -3.49894240e-02,\n",
       "       -3.67923468e-01,  4.79336619e-01, -5.56342185e-01,  4.95318204e-01,\n",
       "       -8.48569274e-01, -1.28043103e+00, -1.33384860e+00,  8.43363106e-01,\n",
       "        7.93342710e-01, -1.04229420e-01, -3.29073459e-01, -3.03841621e-01,\n",
       "       -2.33733922e-01,  9.05461252e-01, -1.67508006e-01,  3.42370570e-02,\n",
       "       -3.72447789e-01, -3.73739541e-01, -2.26284027e+00, -1.18261471e-01,\n",
       "       -1.26988932e-01,  2.25009397e-01, -1.84849098e-01, -1.49167895e+00,\n",
       "        1.36759400e+00,  3.67660403e-01,  6.61720276e-01,  1.44676387e-01,\n",
       "       -6.81932569e-01, -4.91457939e-01, -6.50129199e-01,  8.90649915e-01,\n",
       "       -5.72052896e-02, -7.10406423e-01, -6.27235949e-01,  2.92506099e-01,\n",
       "       -5.92345953e-01,  9.63181376e-01, -5.64981699e-01,  1.28067529e+00,\n",
       "       -5.86007357e-01, -5.58775306e-01, -1.17299318e-01,  9.30862278e-02,\n",
       "        1.35283709e-01, -1.35825539e+00, -3.38868767e-01, -4.87305522e-02,\n",
       "       -2.08923280e-01, -6.58137441e-01,  2.60580331e-01,  4.71050739e-02,\n",
       "       -4.17110324e-02,  1.01680197e-01,  3.80242854e-01, -1.29819393e+00,\n",
       "       -3.68398368e-01, -9.02652740e-01, -3.00415486e-01,  6.74775004e-01,\n",
       "        7.17055559e-01, -4.36148942e-01,  5.19510269e-01, -4.06156331e-02,\n",
       "        4.30808514e-01,  2.15312171e+00, -4.75895107e-01,  2.40578204e-01,\n",
       "        7.68158913e-01,  4.01704401e-01, -4.61992264e-01,  5.62999964e-01,\n",
       "       -9.82755005e-01,  4.07586038e-01,  1.31064683e-01, -4.01774228e-01,\n",
       "        3.23122352e-01,  5.89379549e-01,  1.86119154e-01, -9.73963514e-02,\n",
       "       -7.49026895e-01,  2.80732006e-01, -7.01131701e-01, -2.07642734e-01,\n",
       "       -4.90514934e-03,  8.45640421e-01,  3.89215723e-02,  6.86287463e-01,\n",
       "       -2.21972048e-01, -1.28897130e-01, -1.47411323e+00, -5.46440065e-01,\n",
       "        1.00354552e-01, -1.24380422e+00,  1.22231320e-01,  4.02599871e-02,\n",
       "        4.55493748e-01,  1.14832580e-01, -3.21646184e-01, -5.49730659e-02,\n",
       "       -1.36868799e+00, -3.95232111e-01, -1.10079491e+00, -1.83257967e-01,\n",
       "        5.00513136e-01, -6.95886970e-01, -3.71021509e-01,  3.46946716e-03,\n",
       "       -3.16777945e-01, -2.79341429e-01, -2.52160758e-01, -2.96367973e-01,\n",
       "       -7.61717558e-04,  1.43806744e+00, -1.29467833e+00, -1.67418420e-01,\n",
       "       -2.05776048e+00, -1.14916110e+00,  2.77823150e-01,  1.25197396e-01,\n",
       "       -3.20092738e-01, -4.56347823e-01, -9.81774211e-01, -1.49117303e+00,\n",
       "       -1.07211781e+00, -8.25844169e-01,  1.24006167e-01, -5.14461517e-01,\n",
       "       -7.42927670e-01, -7.13934898e-01, -8.74421597e-01, -2.98259914e-01,\n",
       "        5.76532185e-01, -1.02046430e+00,  5.60910106e-01, -7.75011554e-02,\n",
       "       -6.31595671e-01, -5.08394837e-01, -1.75589919e-01,  4.31026936e-01,\n",
       "       -2.77972370e-01, -3.66616786e-01, -7.55187511e-01, -5.69250882e-01,\n",
       "        8.11786413e-01,  1.10123777e+00,  5.37519872e-01, -1.10424906e-01,\n",
       "        7.98870802e-01, -8.31655264e-02, -1.40386772e+00, -4.81433660e-01,\n",
       "       -5.26669085e-01, -2.64450639e-01,  1.11974478e+00,  1.64115742e-01,\n",
       "       -8.85429502e-01,  1.01623178e+00, -1.27396375e-01,  1.37808585e+00,\n",
       "       -1.07071161e+00, -3.34707558e-01,  1.52925432e-01,  3.71165097e-01,\n",
       "       -7.50269145e-02,  1.11226559e+00, -8.36732686e-01,  2.70821929e-01,\n",
       "       -1.90773213e+00, -8.96402001e-01,  4.79488313e-01,  1.09312963e+00,\n",
       "       -9.06718135e-01, -6.35914952e-02, -3.67257476e-01,  8.18548560e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = get_embedding(transformer, \"здравей\")\n",
    "\n",
    "print(embedding.shape)\n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " zdrʌ vɛj , kʌk stɛ ? \n",
      " dob rɛ sɐm , blʌ go dʌr jɐ . \n",
      " xvɐr ljɐ \n",
      " bɐl gʌr ski ɛ zik \n",
      " ɛ zik bɐl gʌr ski ɛ zik \n",
      " ljɐ to to ɛ mo ɛ to ljo bi mo vrɛ mɛ nʌ go di nʌ tʌ . \n",
      " v pʌr kʌ rʌz lit tjɐ xʌ nɛ vɛ ro jɐt ni tsvɛt jɐ . \n",
      " mo zi kʌ tʌ os po ko jɐ vʌ do ʃʌ tʌ mi slɛd dɐ lɐg rʌ bo tɛn dɛn . \n",
      " vtʃɛ rʌ sɛ srɛʃ tnʌx sɐs stʌr pri jɐ tɛl , ko go to nɛ bjɐx viʒ dʌl go di ni . \n",
      " tʃɛ tɛ nɛ to nʌ kni gi rʌz ʃir jɐ vʌ xo ri zon ti tɛ i o bo gʌt jɐ vʌ rɛt ʃni kʌ . \n"
     ]
    }
   ],
   "source": [
    "print(translate(transformer, \"здравей, как сте?\"))\n",
    "print(translate(transformer, \"Добре съм, благодаря.\"))\n",
    "print(translate(transformer, \"Айрян\"))\n",
    "print(translate(transformer, \"Български език\"))\n",
    "print(translate(transformer, \"език Български език\"))\n",
    "print(translate(transformer, \"Лятото е моето любимо време на годината.\"))\n",
    "print(translate(transformer, \"В парка разцъфтяха невероятни цветя.\"))\n",
    "print(translate(transformer, \"Музиката успокоява душата ми след дълъг работен ден.\"))\n",
    "print(translate(transformer, \"Вчера се срещнах със стар приятел, когото не бях виждал години.\"))\n",
    "print(translate(transformer, \"Четенето на книги разширява хоризонтите и обогатява речника.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
